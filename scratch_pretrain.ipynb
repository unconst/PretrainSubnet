{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# Load the 'wikitext-2' dataset\n",
    "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
    "\n",
    "# Tokenize the text\n",
    "def encode(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=1024, padding='max_length')\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=False)\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(encoded_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Add the EOS token as PAD token to ensure our dataloader doesn't throw an error for sequences of unequal length\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Use CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os; os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add the EOS token as PAD token to ensure our dataloader doesn't throw an error for sequences of unequal length\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Use CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load wikitext-2 dataset\n",
    "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
    "\n",
    "# Define encoding function\n",
    "def encode(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=1024, padding='max_length', return_tensors='pt')\n",
    "\n",
    "# Encode the dataset\n",
    "encoded_dataset = dataset.map(encode, batched=True)\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "dataloader = DataLoader(encoded_dataset, batch_size=8)\n",
    "\n",
    "# Initialize variables\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    if i == 100: break\n",
    "    i += 1\n",
    "    with torch.no_grad():\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        print(\"batch perplexity:\", math.exp(loss.item()))\n",
    "\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "# Compute the average loss over all of the batches.\n",
    "avg_val_loss = total_eval_loss / nb_eval_steps\n",
    "\n",
    "# Measure how long the validation run took.\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"Validation Loss:\", avg_val_loss)\n",
    "print(\"Validation Perplexity:\", math.exp(avg_val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 2\u001b[0m ds \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mcerebras/SlimPajama-627B\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m'\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m'\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, streaming\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/load.py:2109\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2104\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2105\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2106\u001b[0m )\n\u001b[1;32m   2108\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2109\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2110\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2111\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2112\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2113\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2114\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2115\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2116\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2117\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2118\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2119\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2120\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2121\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2122\u001b[0m )\n\u001b[1;32m   2124\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2125\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/load.py:1795\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1794\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1795\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1796\u001b[0m     path,\n\u001b[1;32m   1797\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1798\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1799\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1800\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1801\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1802\u001b[0m )\n\u001b[1;32m   1803\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1804\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/load.py:1476\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1462\u001b[0m             path,\n\u001b[1;32m   1463\u001b[0m             revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m             dynamic_modules_path\u001b[39m=\u001b[39mdynamic_modules_path,\n\u001b[1;32m   1467\u001b[0m         )\u001b[39m.\u001b[39mget_module()\n\u001b[1;32m   1468\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1469\u001b[0m         \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithoutScript(\n\u001b[1;32m   1470\u001b[0m             path,\n\u001b[1;32m   1471\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1472\u001b[0m             data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1473\u001b[0m             data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1474\u001b[0m             download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1475\u001b[0m             download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m-> 1476\u001b[0m         )\u001b[39m.\u001b[39;49mget_module()\n\u001b[1;32m   1477\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[1;32m   1478\u001b[0m     \u001b[39mException\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m ) \u001b[39mas\u001b[39;00m e1:  \u001b[39m# noqa all the attempts failed, before raising the error we should check if the module is already cached.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/load.py:1032\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m metadata_configs \u001b[39m=\u001b[39m MetadataConfigs\u001b[39m.\u001b[39mfrom_dataset_card_data(dataset_card_data)\n\u001b[1;32m   1028\u001b[0m dataset_infos \u001b[39m=\u001b[39m DatasetInfosDict\u001b[39m.\u001b[39mfrom_dataset_card_data(dataset_card_data)\n\u001b[1;32m   1029\u001b[0m patterns \u001b[39m=\u001b[39m (\n\u001b[1;32m   1030\u001b[0m     sanitize_patterns(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files)\n\u001b[1;32m   1031\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m     \u001b[39melse\u001b[39;00m get_data_patterns(base_path, download_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config)\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m data_files \u001b[39m=\u001b[39m DataFilesDict\u001b[39m.\u001b[39mfrom_patterns(\n\u001b[1;32m   1035\u001b[0m     patterns,\n\u001b[1;32m   1036\u001b[0m     base_path\u001b[39m=\u001b[39mbase_path,\n\u001b[1;32m   1037\u001b[0m     allowed_extensions\u001b[39m=\u001b[39mALL_ALLOWED_EXTENSIONS,\n\u001b[1;32m   1038\u001b[0m     download_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_config,\n\u001b[1;32m   1039\u001b[0m )\n\u001b[1;32m   1040\u001b[0m module_name, default_builder_kwargs \u001b[39m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m   1041\u001b[0m     data_files\u001b[39m=\u001b[39mdata_files,\n\u001b[1;32m   1042\u001b[0m     path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m   1043\u001b[0m     download_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_config,\n\u001b[1;32m   1044\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/data_files.py:457\u001b[0m, in \u001b[0;36mget_data_patterns\u001b[0;34m(base_path, download_config)\u001b[0m\n\u001b[1;32m    455\u001b[0m resolver \u001b[39m=\u001b[39m partial(resolve_pattern, base_path\u001b[39m=\u001b[39mbase_path, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_data_files_patterns(resolver)\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m EmptyDatasetError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe directory at \u001b[39m\u001b[39m{\u001b[39;00mbase_path\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain any data files\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/data_files.py:248\u001b[0m, in \u001b[0;36m_get_data_files_patterns\u001b[0;34m(pattern_resolver)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mfor\u001b[39;00m pattern \u001b[39min\u001b[39;00m patterns:\n\u001b[1;32m    247\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m         data_files \u001b[39m=\u001b[39m pattern_resolver(pattern)\n\u001b[1;32m    249\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/data_files.py:332\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    330\u001b[0m     base_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m pattern, storage_options \u001b[39m=\u001b[39m _prepare_path_and_storage_options(pattern, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[0;32m--> 332\u001b[0m fs, _, _ \u001b[39m=\u001b[39m get_fs_token_paths(pattern, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n\u001b[1;32m    333\u001b[0m fs_base_path \u001b[39m=\u001b[39m base_path\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m::\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m://\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mor\u001b[39;00m fs\u001b[39m.\u001b[39mroot_marker\n\u001b[1;32m    334\u001b[0m fs_pattern \u001b[39m=\u001b[39m pattern\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m::\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m://\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/core.py:625\u001b[0m, in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    623\u001b[0m     paths \u001b[39m=\u001b[39m _expand_paths(paths, name_function, num)\n\u001b[1;32m    624\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m--> 625\u001b[0m     paths \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(fs\u001b[39m.\u001b[39;49mglob(paths)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fs\u001b[39m.\u001b[39misdir(f)]\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     paths \u001b[39m=\u001b[39m [paths]\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:580\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     root \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     depth \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m**\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m path \u001b[39melse\u001b[39;00m path[ind \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :]\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 580\u001b[0m allpaths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind(root, maxdepth\u001b[39m=\u001b[39;49mdepth, withdirs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, detail\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    581\u001b[0m \u001b[39m# Escape characters special to python regex, leaving our supported\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[39m# special characters in place.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[39m# See https://www.gnu.org/software/bash/manual/html_node/Pattern-Matching.html\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[39m# for shell globbing details.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m pattern \u001b[39m=\u001b[39m (\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m^\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    587\u001b[0m     \u001b[39m+\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:481\u001b[0m, in \u001b[0;36mAbstractFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    480\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m--> 481\u001b[0m \u001b[39mfor\u001b[39;00m _, dirs, files \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwalk(path, maxdepth, detail\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m withdirs:\n\u001b[1;32m    483\u001b[0m         files\u001b[39m.\u001b[39mupdate(dirs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:451\u001b[0m, in \u001b[0;36mAbstractFileSystem.walk\u001b[0;34m(self, path, maxdepth, topdown, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dirs:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwalk(\n\u001b[1;32m    452\u001b[0m         full_dirs[d],\n\u001b[1;32m    453\u001b[0m         maxdepth\u001b[39m=\u001b[39mmaxdepth,\n\u001b[1;32m    454\u001b[0m         detail\u001b[39m=\u001b[39mdetail,\n\u001b[1;32m    455\u001b[0m         topdown\u001b[39m=\u001b[39mtopdown,\n\u001b[1;32m    456\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    457\u001b[0m     )\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m topdown:\n\u001b[1;32m    460\u001b[0m     \u001b[39m# Yield after recursion if walking bottom up\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[39myield\u001b[39;00m path, dirs, files\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:451\u001b[0m, in \u001b[0;36mAbstractFileSystem.walk\u001b[0;34m(self, path, maxdepth, topdown, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dirs:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwalk(\n\u001b[1;32m    452\u001b[0m         full_dirs[d],\n\u001b[1;32m    453\u001b[0m         maxdepth\u001b[39m=\u001b[39mmaxdepth,\n\u001b[1;32m    454\u001b[0m         detail\u001b[39m=\u001b[39mdetail,\n\u001b[1;32m    455\u001b[0m         topdown\u001b[39m=\u001b[39mtopdown,\n\u001b[1;32m    456\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    457\u001b[0m     )\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m topdown:\n\u001b[1;32m    460\u001b[0m     \u001b[39m# Yield after recursion if walking bottom up\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[39myield\u001b[39;00m path, dirs, files\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:414\u001b[0m, in \u001b[0;36mAbstractFileSystem.walk\u001b[0;34m(self, path, maxdepth, topdown, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m detail \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    413\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     listing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mls(path, detail\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    415\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mFileNotFoundError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m):\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m detail:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py:271\u001b[0m, in \u001b[0;36mHfFileSystem.ls\u001b[0;34m(self, path, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     tree_iter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mchain([tree_item], tree_iter)\n\u001b[1;32m    270\u001b[0m child_infos \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 271\u001b[0m \u001b[39mfor\u001b[39;00m tree_item \u001b[39min\u001b[39;00m tree_iter:\n\u001b[1;32m    272\u001b[0m     child_info \u001b[39m=\u001b[39m {\n\u001b[1;32m    273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: path_prefix \u001b[39m+\u001b[39m tree_item[\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    274\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m: tree_item[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    275\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: tree_item[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    276\u001b[0m     }\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m tree_item[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py:300\u001b[0m, in \u001b[0;36mHfFileSystem._iter_tree\u001b[0;34m(self, path, revision)\u001b[0m\n\u001b[1;32m    296\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/api/\u001b[39m\u001b[39m{\u001b[39;00mresolved_path\u001b[39m.\u001b[39mrepo_type\u001b[39m}\u001b[39;00m\u001b[39ms/\u001b[39m\u001b[39m{\u001b[39;00mresolved_path\u001b[39m.\u001b[39mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m/tree/\u001b[39m\u001b[39m{\u001b[39;00msafe_quote(resolved_path\u001b[39m.\u001b[39mrevision)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mresolved_path\u001b[39m.\u001b[39mpath_in_repo\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mrstrip(\n\u001b[1;32m    297\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m )\n\u001b[1;32m    299\u001b[0m headers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api\u001b[39m.\u001b[39m_build_hf_headers()\n\u001b[0;32m--> 300\u001b[0m \u001b[39myield from\u001b[39;00m paginate(path, params\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mexpand\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m}, headers\u001b[39m=\u001b[39mheaders)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/huggingface_hub/utils/_pagination.py:44\u001b[0m, in \u001b[0;36mpaginate\u001b[0;34m(path, params, headers)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mwhile\u001b[39;00m next_page \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPagination detected. Requesting next page: \u001b[39m\u001b[39m{\u001b[39;00mnext_page\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     r \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mget(next_page, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m     45\u001b[0m     hf_raise_for_status(r)\n\u001b[1;32m     46\u001b[0m     \u001b[39myield from\u001b[39;00m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"cerebras/SlimPajama-627B\",  'default', split='test', streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = ds.shuffle(buffer_size = 100, seed = 1 )\n",
    "next(iter(dss.skip(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"togethercomputer/RedPajama-Data-1T\", 'default', split='train', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.iterable_dataset.IterableDataset at 0x7fe3785ef610>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"\\\\section{Introduction}\\nLet $G$ be a simple undirected graph with the \\\\textit{vertex set} $V(G)$ and the \\\\textit{edge set} $E(G)$. A vertex with degree one is called a \\\\textit{pendant vertex}. The distance between the vertices $u$ and $v$ in graph $G$ is denoted by $d_G(u,v)$. A cycle $C$ is called \\\\textit{chordless} if $C$ has no \\\\textit{cycle chord} (that is an edge not in the edge set of $C$ whose endpoints lie on the vertices of $C$).\\nThe \\\\textit{Induced subgraph} on vertex set $S$ is denoted by $\\\\langle S\\\\rangle$. A path that starts in $v$ and ends in $u$ is denoted by $\\\\stackrel\\\\frown{v u}$.\\nA \\\\textit{traceable} graph is a graph that possesses a Hamiltonian path.\\nIn a graph $G$, we say that a cycle $C$ is \\\\textit{formed by the path} $Q$ if $ | E(C) \\\\setminus E(Q) | = 1 $. So every vertex of $C$ belongs to $V(Q)$.\\n\\nIn 2011 the following conjecture was proposed:\\n\\\\begin{conjecture}(Hoffmann-Ostenhof \\\\cite{hoffman})\\nLet $G$ be a connected cubic graph. Then $G$ has a decomposition into a spanning tree, a matching and a family of cycles.\\n\\n\\\\end{conjecture}\\nConjecture \\\\theconjecture$\\\\,$ also appears in Problem 516 \\\\cite{cameron}. There are a few partial results known for Conjecture \\\\theconjecture. Kostochka \\\\cite{kostocha} noticed that the Petersen graph, the prisms over cycles, and many other graphs have a decomposition desired in Conjecture \\\\theconjecture. Ozeki and Ye \\\\cite{ozeki} proved that the conjecture holds for 3-connected cubic plane graphs. Furthermore, it was proved by Bachstein \\\\cite{bachstein} that Conjecture \\\\theconjecture$\\\\,$ is true for every 3-connected cubic graph embedded in torus or Klein-bottle. Akbari, Jensen and Siggers \\\\cite[Theorem 9]{akbari} showed that Conjecture \\\\theconjecture$\\\\,$ is true for Hamiltonian cubic graphs.\\n\\nIn this paper, we show that Conjecture \\\\theconjecture$\\\\,$ holds for traceable cubic graphs.\\n\\\\section{Results}\\nBefore proving the main result, we need the following lemma.\\n\\\\begin{lemma}\\n\\\\label{lemma:1}\\nLet $G$ be a cubic graph. Suppose that $V(G)$ can be partitioned into a tree $T$ and finitely many cycles such that there is no edge between any pair of cycles (not necessarily distinct cycles), and every pendant vertex of $T$ is adjacent to at least one vertex of a cycle. Then, Conjecture \\\\theconjecture$\\\\,$ holds for $G$.\\n\\\\end{lemma}\\n\\\\begin{proof}\\nBy assumption, every vertex of each cycle in the partition is adjacent to exactly one vertex of $T$. Call the set of all edges with one endpoint in a cycle and another endpoint in $T$ by $Q$.\\nClearly, the induced subgraph on $E(T) \\\\cup Q$ is a spanning tree of $G$. We call it $T'$. Note that every edge between a pendant vertex of $T$ and the union of cycles in the partition is also contained in $T'$. Thus, every pendant vertex of $T'$ is contained in a cycle of the partition. Now, consider the graph $H = G \\\\setminus E(T')$. For every $v \\\\in V(T)$, $d_H(v) \\\\leq 1$. So Conjecture \\\\theconjecture$\\\\,$ holds for $G$. \\\\vspace{1em}\\n\\\\end{proof}\\n\\n\\n\\\\noindent\\\\textbf{Remark 1.}\\n\\\\label{remark:1}\\nLet $C$ be a cycle formed by the path $Q$. Then clearly there exists a chordless cycle formed by $Q$.\\n\\nNow, we are in a position to prove the main result.\\n\\n\\\\begin{theorem}\\nConjecture \\\\theconjecture$\\\\,$ holds for traceable cubic graphs.\\n\\\\end{theorem}\\n\\\\begin{proof}\\nLet $G$ be a traceable cubic graph and $P : v_1, \\\\dots, v_n$ be a Hamiltonian path in $G$. By \\\\cite[Theorem 9]{akbari}, Conjecture A holds for $v_1 v_n  \\\\in E(G)$. Thus we can assume that $v_1 v_n  \\\\notin E(G)$. Let $v_1 v_j, v_1 v_{j'}, v_i v_n, v_{i'} v_n \\\\in E(G)\\\\setminus E(P)$  and $j' < j < n$, $1 < i < i'$. Two cases can occur:\\n\\\\begin{enumerate}[leftmargin=0pt,label=]\\n\\\\item\\n\\\\textbf{Case 1.}\\nAssume that $i < j$. Consider the following graph in Figure \\\\ref{fig:overlapping} in which the thick edges denote the path $P$. Call the three paths between $v_j$ and $v_i$, from the left to the right, by $P_1$, $P_2$ and $P_3$, respectively (note that $P_1$ contains the edge $e'$ and $P_3$ contains the edge $e$).\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=40mm]{engImages/overlapping.pdf}\\n    \\\\caption{Paths $P_1$, $P_2$ and $P_3$}\\n    \\\\label{fig:overlapping}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\n\\nIf $P_2$ has order $2$, then $G$ is Hamiltonian and so by \\\\cite[Theorem 9]{akbari} Conjecture \\\\theconjecture$\\\\,$ holds. Thus we can assume that $P_1$, $P_2$ and $P_3$ have order at least $3$. Now, consider the following subcases:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=0pt,label=]\\n\\\\label{case:1}\\n\\\\item \\\\textbf{Subcase 1.} There is no edge between $V(P_r)$ and $V(P_s)$ for $1 \\\\leq r < s \\\\leq 3$. Since every vertex of $P_i$ has degree 3 for every $i$, by \\\\hyperref[remark:1]{Remark 1}$\\\\,$ there are two chordless cycles $C_1$ and $C_2$ formed by $P_1$ and $P_2$, respectively.\\nDefine a tree $T$ with the edge set\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle\\\\Big) \\\\bigcap \\\\big(\\\\bigcup_{i=1}^3 E(P_i)\\\\big).$$\\nNow, apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\\\\\\\\\n\\n\\\\item \\\\textbf{Subcase 2.}\\n\\\\label{case:edge}\\nThere exists at least one edge between some $P_r$ and $P_s$, $r<s$. With no loss of generality, assume that $r=1$ and $s=2$. Suppose that $ab \\\\in E(G)$, where $a \\\\in V(P_1)$, $b \\\\in V(P_2)$ and $d_{P_1}(v_j, a) + d_{P_2}(v_j, b)$ is minimum.\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=40mm]{engImages/ab.pdf}\\n    \\\\caption{The edge $ab$ between $P_1$ and $P_2$}\\n    \\\\label{fig:ab}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\nThree cases occur: \\\\\\\\\\n\\n(a) There is no chordless cycle formed by either of the paths $\\\\stackrel\\\\frown{v_j a}$ or $\\\\stackrel\\\\frown{v_j b}$. Let $C$ be the chordless cycle $\\\\stackrel\\\\frown{v_j a}\\\\stackrel\\\\frown{ b v_j}$. Define $T$ with the edge set\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus V(C)\\\\rangle\\\\Big) \\\\bigcap \\\\big(\\\\bigcup_{i=1}^3 E(P_i)\\\\big).$$\\nNow, apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T,C\\\\}$.\\t\\\\\\\\\\n\\n(b) There are two chordless cycles, say $C_1$ and $C_2$, respectively formed by the paths $\\\\stackrel\\\\frown{v_j a}$ and $\\\\stackrel\\\\frown{v_j b}$. Now, consider the partition $C_1$, $C_2$ and the tree induced on the following edges,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle\\\\Big) \\\\; \\\\bigcap \\\\; E\\\\Big(\\\\bigcup_{i=1}^3 P_i\\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\\\\\\\\\n\\n(c) With no loss of generality, there exists a chordless cycle formed by the path $\\\\stackrel\\\\frown{v_j a}$ and there is no chordless cycle formed by the path $\\\\stackrel\\\\frown{v_j b}$.\\nFirst, suppose that for every chordless cycle $C_t$ on $\\\\stackrel\\\\frown{v_j a}$, at least one of the vertices of $C_t$ is adjacent to a vertex in $V(G) \\\\setminus V(P_1)$.\\nWe call one of the edges with one end in $C_t$ and other endpoint in $V(G) \\\\setminus V(P_1)$ by $e_t$. Let $v_j=w_0, w_1, \\\\dots, w_l=a$ be all vertices of the path $\\\\stackrel\\\\frown{v_j a}$ in $P_1$. Choose the shortest path $w_0 w_{i_1} w_{i_2} \\\\dots w_l$ such that $0 < i_1 < i_2 < \\\\dots < l$.\\nDefine a tree $T$ whose edge set is the thin edges in Figure \\\\ref{fig:deltaCycle}.\\\\\\\\\\nCall the cycle $w_0 w_{i_1} \\\\dots w_l \\\\stackrel\\\\frown{b w_0}$ by $C'$. Now, by removing $C'$, $q$ vertex disjoint paths $Q_1, \\\\dots, Q_q$ which are contained in $\\\\stackrel\\\\frown{v_j a}$ remain. Note that there exists a path of order $2$ in $C'$ which by adding this path to $Q_i$ we find a cycle $C_{t_i}$, for some $i$. Hence there exists an edge $e_{t_i}$ connecting $Q_i$ to $V(G) \\\\setminus V(P_1)$. Now, we define a tree $T$ whose the edge set is,\\n$$\\\\quad\\\\quad\\\\quad \\\\bigg( E\\\\Big(\\\\langle V(G) \\\\setminus V(C') \\\\rangle \\\\Big)\\\\; \\\\bigcap \\\\; \\\\Big(\\\\bigcup_{i=1}^3 E(P_i)\\\\Big) \\\\bigg) \\\\bigcup \\\\Big(\\\\big\\\\{e_{t_i} \\\\mid 1 \\\\leq i \\\\leq q \\\\big\\\\} \\\\Big).$$\\nApply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T,C'\\\\}$.\\\\\\\\\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=40mm]{engImages/deltaCycle.pdf}\\n    \\\\caption{The cycle $C'$ and the tree $T$}\\n       \\\\label{fig:deltaCycle}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\nNext, assume that there exists a cycle $C_1$ formed by $\\\\stackrel\\\\frown{v_j a}$ such that none of the vertices of $C_1$ is adjacent to $V(G) \\\\setminus V(P_1)$. Choose the smallest cycle with this property. Obviously, this cycle is chordless. Now, three cases can be considered:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=5pt,label=(\\\\roman*)]\\n\\\\item There exists a cycle $C_2$ formed by $P_2$ or $P_3$. Define the partition $C_1$, $C_2$ and a tree with the following edge set,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( \\\\bigcup_{i=1}^3 E(P_i) \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\\\\\\\\\n\\n\\\\item There is no chordless cycle formed by $P_2$ and by $P_3$, and there is at least one edge between $V(P_2)$ and $V(P_3)$. Let $ab \\\\in E(G)$, $a \\\\in V(P_2)$ and $b \\\\in V(P_3)$ and moreover $d_{P_2}(v_j, a) + d_{P_3}(v_j,b)$ is minimum. Notice that the cycle $\\\\stackrel\\\\frown{v_j a} \\\\stackrel\\\\frown{b v_j}$ is chordless. Let us call this cycle by $C_2$. Now, define the partition $C_2$ and a tree with the following edge set,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus V(C_2)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( \\\\bigcup_{i=1}^3 E(P_i) \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\\\\\\\\\n\\n\\\\item There is no chordless cycle formed by $P_2$ and by $P_3$, and there is no edge between $V(P_2)$ and $V(P_3)$. Let $C_2$ be the cycle consisting of two paths $P_2$ and $P_3$. Define the partition $C_2$ and a tree with the following edge set,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus V(C_2)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( \\\\bigcup_{i=1}^3 E(P_i) \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\n\\n\\\\end{enumerate}\\n\\n\\n\\\\end{enumerate}\\n\\n\\\\vspace{5mm}\\n\\\\item\\n\\\\textbf{Case 2.}\\n\\\\label{case:2}\\nAssume that $j < i$ for all Hamiltonian paths. Among all Hamiltonian paths consider the  path such that $i'-j'$ is maximum. Now, three cases can be considered:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=0pt,label=]\\n\\\\item \\\\textbf{Subcase 1.} There is no $s < j'$ and $t > i'$ such that $v_s v_t \\\\in E(G)$. By \\\\hyperref[remark:1]{Remark 1} $\\\\,$ there are two chordless cycles $C_1$ and $C_2$, respectively formed by the paths $v_1 v_{j'}$ and $v_{i'} v_n$. By assumption there is no edge $xy$, where $x \\\\in V(C_1)$ and $y \\\\in V(C_2)$.\\nDefine a tree $T$ with the edge set:\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_{i'}v_n, v_{j'}v_1\\\\} \\\\Big).$$\\nNow, apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\\\\\\\\\n\\n\\\\item \\\\textbf{Subcase 2.}\\n\\\\label{subcase:22} There are at least four indices $s, s' < j$ and $t, t' > i$ such that $v_s v_t, v_{s'} v_{t'} \\\\in E(G)$. Choose four indices $g, h < j$ and $e, f > i$ such that $v_h v_e, v_g v_f \\\\in E(G)$ and $|g-h| + |e-f|$ is minimum.\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=90mm]{engImages/case2-subcase2.pdf}\\n    \\\\caption{Two edges $v_h v_e$ and $v_g v_f$}\\n    \\\\label{fig:non-overlapping}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\nThree cases can be considered:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=0pt,label=(\\\\alph*)]\\n\\\\item There is no chordless cycle formed by $\\\\stackrel\\\\frown{v_g v_h}$ and by $\\\\stackrel\\\\frown{v_e v_f}$.\\n\\nConsider the cycle $\\\\stackrel\\\\frown{v_g v_h} \\\\stackrel\\\\frown{v_e v_f}v_g$ and call it $C$. Now, define a tree $T$ with the edge set,\\n$$\\\\,\\\\,\\\\,E\\\\Big(\\\\langle V(G) \\\\setminus V(C)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\napply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C\\\\}$.\\\\\\\\\\n\\n\\\\item With no loss of generality, there exists a chordless cycle formed by $\\\\stackrel\\\\frown{v_e v_f}$ and there is no chordless cycle formed by the path $\\\\stackrel\\\\frown{v_g v_h}$. First suppose that there is a chordless cycle $C_1$ formed by $\\\\stackrel\\\\frown{v_e v_f}$ such that there is no edge between $V(C_1)$ and $\\\\{v_1, \\\\dots, v_j\\\\}$. By \\\\hyperref[remark:1]{Remark 1} $,$ there exists a chordless cycle $C_2$ formed by $\\\\stackrel\\\\frown{v_1 v_j}$. By assumption there is no edge between $V(C_1)$ and $V(C_2)$. Now, define a tree $T$ with the edge set,\\n\\n$$\\\\quad\\\\quad\\\\quad\\\\quad E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\n\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\n\\n$\\\\;$ Next assume that for every cycle $C_r$ formed by $\\\\stackrel\\\\frown{v_e v_f}$, there are two vertices $x_r \\\\in V(C_r)$ and $y_r \\\\in \\\\{v_1, \\\\dots, v_j\\\\}$ such that $x_r y_r \\\\in E(G)$. Let $v_e=w_0, w_1, \\\\dots, w_l=v_f$ be all vertices of the path $\\\\stackrel\\\\frown{v_e v_f}$ in $P$. Choose the shortest path $w_0 w_{i_1} w_{i_2} \\\\dots w_l$ such that $0 < i_1 < i_2 < \\\\dots < l$. Consider the cycle $w_0 w_{i_1} \\\\dots w_l \\\\stackrel\\\\frown{v_g v_h}$ and call it $C$. Now, by removing $C$, $q$ vertex disjoint paths $Q_1, \\\\dots, Q_q$ which are contained in $\\\\stackrel\\\\frown{v_e v_f}$ remain. Note that there exists a path of order $2$ in $C$ which by adding this path to $Q_i$ we find a cycle $C_{r_i}$, for some $i$. Hence there exists an edge $x_{r_i} y_{r_i}$ connecting $Q_i$ to $V(G) \\\\setminus V(\\\\stackrel\\\\frown{v_e v_f})$. We define a tree $T$ whose edge set is the edges,\\n$$\\\\quad\\\\quad\\\\quad\\\\quad\\\\quad\\\\quad E\\\\Big(\\\\langle V(G) \\\\setminus V(C)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\cup \\\\big\\\\{x_{r_i} y_{r_i} \\\\mid 1 \\\\leq i \\\\leq q\\\\big\\\\} \\\\Big),$$\\nthen apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$ on the partition $\\\\{T, C\\\\}$.\\\\\\\\\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=90mm]{engImages/deltaNonOverlapping.pdf}\\n    \\\\caption{The tree $T$ and the shortest path $w_0 w_{i_1}\\\\dots w_l$}\\n    \\\\label{fig:delta-non-overlapping}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\n\\\\item There are at least two chordless cycles, say $C_1$ and $C_2$ formed by the paths $\\\\stackrel\\\\frown{v_g v_h}$ and $\\\\stackrel\\\\frown{v_e v_f}$, respectively. Since $|g-h| + |e-f|$ is minimum, there is no edge $xy \\\\in E(G)$ with $x \\\\in V(C_1)$ and $y \\\\in V(C_2)$. Now, define a tree $T$ with the edge set,\\n$$\\\\quad\\\\quad\\\\quad\\\\quad E\\\\Big( \\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1 v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\\\\\\\\\n\\\\end{enumerate}\\n\\n\\\\item \\\\textbf{Subcase 3.} There exist exactly two indices $s,t$,  $s < j' < i' < t$ such that $v_s v_t \\\\in E(G)$ and there are no two other indices $s', t'$ such that $s' < j < i < t'$ and $v_{s'} v_{t'} \\\\in E(G)$. We can assume that there is no cycle formed by  $\\\\stackrel\\\\frown{v_{s+1} v_j}$ or $\\\\stackrel\\\\frown{v_i v_{t-1}}$, to see this by symmetry consider a cycle $C$ formed by $\\\\stackrel\\\\frown{v_{s+1} v_j}$. By \\\\hyperref[remark:1]{Remark 1} $\\\\,$ there exist chordless cycles $C_1$ formed by $\\\\stackrel\\\\frown{v_{s+1} v_j}$ and $C_2$ formed by $\\\\stackrel\\\\frown{v_{i} v_n}$. By assumption $v_s v_t$ is the only edge such that $s < j$ and $t > i \\\\;$. Therefore,  there is no edge between $V(C_1)$ and  $V(C_2)$. Now, let $T$ be a tree defined by the edge set,\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition \\\\{$T$, $C_1$, $C_2$\\\\}.\\\\\\\\\\n\\n$\\\\quad$Furthermore, we can also assume that either $s \\\\neq j'-1$  or $t \\\\neq i'+1$, otherwise we have the Hamiltonian cycle $\\\\stackrel\\\\frown{v_1 v_s} \\\\stackrel\\\\frown{v_t v_n} \\\\stackrel\\\\frown{v_{i'} v_{j'}} v_1$ and by \\\\cite[Theorem 9]{akbari} Conjecture \\\\theconjecture$\\\\,$ holds.\\n\\n$\\\\quad$By symmetry, suppose that $s \\\\neq j'-1$. Let $v_k$ be the vertex adjacent to $v_{j'-1}$, and $k \\\\notin \\\\{j'-2, j'\\\\}$. It can be shown that $k > j'-1$, since otherwise by considering the Hamiltonian path $P': \\\\; \\\\stackrel\\\\frown{ v_{k+1} v_{j'-1}}\\\\stackrel\\\\frown{v_k v_1} \\\\stackrel\\\\frown{v_{j'} v_n}$,  the new $i'-j'$ is greater than the old one and this contradicts our assumption about $P$ in the \\\\hyperref[case:2]{Case 2}.\\n\\n$\\\\quad$We know that $j' < k < i$. Moreover, the fact that  $\\\\stackrel\\\\frown{v_{s+1} v_j}$ does not form a cycle contradicts the case that $j' < k \\\\le j$. So $j < k < i$. Consider two cycles $C_1$ and $C_2$, respectively with the vertices $v_1 \\\\stackrel\\\\frown{v_{j'} v_{j}} v_1$ and $v_n \\\\stackrel\\\\frown{v_{i'} v_{i}} v_n$. The cycles $C_1$ and $C_2$ are chordless, otherwise there exist cycles formed by the paths $\\\\stackrel\\\\frown{v_{s+1} v_j}$ or $\\\\stackrel\\\\frown{v_i v_{t-1}}$. Now, define a tree $T$ with the edge set\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_s v_t, v_k v_{j'-1}\\\\} \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition \\\\{$T$, $C_1$, $C_2$\\\\}.\\n\\\\end{enumerate}\\n\\\\end{enumerate}\\n\\\\end{proof}\\n\\n\\\\noindent\\\\textbf{Remark 2.}\\n\\\\label{remark:2}\\nIndeed, in the proof of the previous theorem we showed a stronger result, that is, for every traceable cubic graph there is a decomposition with at most two cycles.\\n\\n\",\n",
       " 'meta': \"{'timestamp': '2016-07-19T02:04:55', 'yymm': '1607', 'arxiv_id': '1607.04768', 'language': 'en', 'url': 'https://arxiv.org/abs/1607.04768'}\",\n",
       " 'red_pajama_subset': 'arxiv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size = 50, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "# Define a list with your paths\n",
    "paths = ['data/0.parquet', 'data/1.parquet', 'data/2.parquet', 'data/3.parquet', 'data/4.parquet',\n",
    "         'data/5.parquet', 'data/6.parquet', 'data/7.parquet', 'data/8.parquet', 'data/9.parquet']\n",
    "\n",
    "paths = [os.path.join('/home/jason/revolution', path) for path in paths]\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('parquet', data_files=paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Vladen \"Saviour\" Dvoretsky is the support for Sector One and is also a coach for Future Perfect WLGaming.\\nFounded his own team called Future Perfect and competed within one of their divisions, Future Perfect Zaun.\\nHas been challenger throughout seasons 5, 6, 7, and 8.',\n",
       " 'meta': {'redpajama_set_name': 'RedPajamaC4'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss=dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dss['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Not very long ago if one were to suggest exploring Katowice by Bike one might have questioned your sanity. Those days are long gone however and after years of recent infrastructure improvements and new investments in world class architecture, greater Katowice is an exciting and exceedingly eclectic destination to discover on two wheels. Follow IYP as we show you around some of the best spots and give you some survival tips for getting the most out of a bike day trip in Katowice.\\nOur grand adventure began outside the centrally located angelo Hotel where Silesiatrip.pl have one of their rental bike pickup points. You can rent a bike right at the Hotel reception and return whenever you're done. Silesiatrip.pl also have bike pickup points at other Hotels in the city or you can arrange for a rental bike pickup from their ul. Mariacki headquarters. Alternatively you can pick up a rental bike from one of the dozen or so City By Bike rental stations scattered around the city/region.\\nStarting from the angelo Hotel we set a course for Silesia Park. Using the two-page Katowice City Map from the back of the guide (ps. 84-85) we planned our course from Sokolska Street to the park. We rolled North and crossed the upper part of the four lane highway that makes up Chorzowska Ave on foot. We made our way to the bike path that parallels the tram lines that head Northwest towards Chorzów. The bike path is shared with a pedestrian path but well-marked. It was smooth sailing all the way to Silesia City Center when the signs clearly mark that bikes should head under a pedestrian tunnel to the left side of the highway. Perhaps we misunderstood the signage but we followed suit only to find ourselves in a parking lot of a car dealership on the other side with no further bike signage in site. Force of habit drew us to the sidewalk with no clear bike lane. We awkwardly continued to make our way Northwest again, this time with oncoming traffic rushing towards us on Chorzowska.\\nOnce we passed the Silesia City Center we could see construction where the bike lane on the opposing side would be. Upon further inspection it seems the bike/pedestrian path on the North side of Chorzowska Ave is currently undergoing maintenance. Keep this in mind as it may be open again in the near future. Nevertheless, we continued our journey onward and finally crossed back over to the North side at the Southernmost tip of Silesia Park where Chorzowska Ave intersects Złota Street. There isn't actually a direct entrance to the park here as it is the entrance to the Silesian Amusement Park. So we followed a pedestrian path North along Złota Street and finally entered the giant park on a marked path just after the Gondola/Ski lift entrance.\\nWe sped through the park and enjoyed the two wheeled freedom to explore Silesia Park's vast natural beauty and many attractions at our own pace.The first thing that caught our eye was the gorgeous Rosarium which was in the process of being pruned by a team of gardeners. We weaved in and out of rows of bushes and beds filled with all shapes and sizes of colorful roses. We were highly fortunate to have embarked on our Silesian cycling trip on a gorgeous early Summer day.\\nWe continued on lazily winding our way through the many pedestrian pathways of the park and quickly arrived to the Kontener Cooltury (p. 58). This pleasure island of tranquility comes alive during the weekend when it hosts a hugely popular concert as well as plenty of burgers, beers and basking in the Silesian sun. Nothing was on at the moment so we sped Northwestward past the central pond and took a turn North to hunt down the Silesian Sculpture Garden. The route took us uphill and we had to avoid some fallen limbs on the pedestrian trails as a storm had passed through earlier in the day. Once we finally found the Sculpture Garden we took a short break to admire the beautiful and sometimes oddball sculptures sunken deep into the forest and fields of the Northern stretches of the park. For more ambitious riders there is an official cycle route which is clearly marked and circumnavigates most of the park on well-marked and well-paved roads. We came close to bisecting this path but being the amateur enthusiasts that we are, we avoided taking this route entirely and decided instead to double back and head for some refreshments.\\nWe sped happily downhill through more felled brush and some other back trails and ended up near the entrance to the Zoo. It was here we saw the familiar green sign of the Rebel Garden and chose its lovely summer garden to plan the next phase of our adventure. Rebel Garden is a bar, pub and somewhat of a cult favourite that regularly holds open air concerts on their back deck and in front of the gilded gates of the Zoo. We grabbed a local Silesian beverage, took a load off and opened up our trusty IYP map to plan our next move. We were torn between heading due South to the Valley of Three Ponds (where the Off Festival is held) or due East to cruise around Nikoszowiec. Both destinations have their pros and cons but the lateness of the hour dictated that Nikoszowiec was the safest option as it looked to be pretty much a bee line from Silesia Park and we had to be back in the city centre before nightfall.\\nSo we packed up and jetted out of the park the same way we came in. We contemplated taking an alternate route back to the city centre but after taking a slight detour through some side streets we made our way back to Chorzowska Ave and followed the same route back Southeast. This time however we sped past Sokolska Street on the bike path and headed straight for the Spodek. The great infrastructure redevelopment of the city centre also saw extensive bike paths built including a ramp that allows cyclists to ascend the eye of the city (formerly known as Oko Miasto, now as Królestwa), which offers the best panoramic views of the new and improved downtown skyline. We paused for a few seconds to take some Kato glamour shots and then continued on our way weaving through the city's newest architectural marvels.\\nWe whizzed by the Spodek and past the new International Convention Center with its angular grass roof terracing and then headed straight for the pedestrian/bike bridge that crosses over to NOSPR. The glorious brick building and the surrounding squares have been so deftly designed that there is ample space for an outdoor restaurant, a gaggle of gawking tourists, several sly fountains and speeding cyclists, without any collisions. We resisted the urge to grab a bite at Cadenza and instead continued on our way. In front of the new Silesian Museum we were faced with a choice of whether to cross over Aleja Walentego Roźdzeńskiego (aka Chorzowska Ave on the West side of Królestwa). It appears that there is a bike path on both sides of the Aleja (Avenue) however looking at the map we assumed at some point we would have to turn right to head towards Nikoszowiec so we chose to cross over the pedestrian bridge to the South of the Avenue and continue Eastward.\\nWe were cruising smoothly when all of a sudden the bike path seemed to disappear just North of the Novotel. Since cycling on the busy 3-lane Avenue was totally out of the question on our rented city bike, we started to use our cyclist's intuition and went a bit freestyle. We headed South for a block until we found another cyclist who seemed to be heading in the same direction, so we followed him. He led us to an amazing secluded canal (see picture) that had two paths on either side both heading due East. We couldn't believe our luck and without thinking we sped off down the canal. We ducked under branches and admired the shady park tucked under the noisy Avenue above when all of a sudden the path ended abruptly in thick brush. We could see across the canal that the path also ended but there was an outlet to the street. We were forced to double back to the last overpass we had just gone under. The overpass turned out to be Bogucicka Street and it led us South to the May 1st Boulevard (1 Maja) where we were once again reunited with an official bike lane.\\nOnce we were on May 1st it was pretty much smooth sailing biking due East. There is a fairly well marked Bike path that goes straight to Nikoszowiec and avoids the many overpasses and underpasses of the Silesian highway system. Keep your wits about you and in about 20 minutes you can make it to the first stop for any trip to Nikoszowiec, the Wilson Shaft Gallery. We took a quick peak into the giant gallery which is currently hosting the Art Naif Festival through mid August and then remounted and headed for the heart of the bucolic workers district. In under 5 minutes we were parked up under St. Anne's Church flashbulbs flying. We circumnavigated the whole of the district several times although from the look on the locals faces, they have yet to see many renegade tourist bikers in these parts. We grabbed another refreshing drink at Riksza Pub, our favourite Nikoszowiec haunt. We noticed the sun was beginning to set so we saddled up one last time for the return journey.\\nWe took the exact same route to get back to the city center although this time we kept following the May 1st boulevard until it turned into Warszawska Street and then we followed Warszawska until the start of ul. Mariacka. We did a quick buzz of the pedestrian thoroughfare from East to West to take in the sights of the gathering crowds of early summer revellers and then bee-lined it for the Rynek to see if all the new construction had made it more bike friendly. Much to our delight, the wide open spaces and open design of the new Rynek is not only bike friendly but the palm trees, beach loungers and flowing river mean it's also sunbather friendly! We took our last photo as the sun dropped lower on the horizon before we made our way back to the angelo Hotel to return our noble green steed. We had a great day exploring some of the best hidden spots the city has to offer and were generally impressed with the cycling infrastructure Katowice has in place and which only looks to increase in the near future. While we certainly encourage you to take the same routes as us (and definitely rent a mean green Silesiatrip.pl bike), greater Silesia is filled with even more amazing architecture, an abundance of parks and plenty of post industrial curiosities well worth exploring on two wheels.\",\n",
       " 'meta': {'redpajama_set_name': 'RedPajamaC4'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget 'https://data.together.xyz/redpajama-data-1T/v1.0.0/urls.txt'\n",
    "while read line; do\n",
    "    dload_loc=${line#https://data.together.xyz/redpajama-data-1T/v1.0.0/}\n",
    "    mkdir -p $(dirname $dload_loc)\n",
    "    wget \"$line\" -O \"$dload_loc\"\n",
    "done < urls.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jason/revolution/data/redpajama/arxiv/arxiv_023827cd-7ee8-42e6-aa7b-661731f4c70f.jsonl',\n",
       " '/home/jason/revolution/data/redpajama/arxiv/arxiv_024de5df-1b7f-447c-8c3a-51407d8d6732.jsonl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Use glob to find all .jsonl files in the downloaded data\n",
    "# This will search in the current directory and all its subdirectories\n",
    "file_paths = glob.glob('/home/jason/revolution/data/redpajama/**/*.jsonl', recursive=True)\n",
    "file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'meta']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open the first file from your dataset\n",
    "with open(file_paths[0], 'r') as f:\n",
    "    # Read the first line (i.e., the first JSON object)\n",
    "    line = f.readline()\n",
    "\n",
    "# Parse the JSON line\n",
    "data = json.loads(line)\n",
    "\n",
    "# Print the keys (field names) of the JSON object\n",
    "fields = list(data.keys())\n",
    "fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"\\\\section{Introduction}\\nLet $G$ be a simple undirected graph with the \\\\textit{vertex set} $V(G)$ and the \\\\textit{edge set} $E(G)$. A vertex with degree one is called a \\\\textit{pendant vertex}. The distance between the vertices $u$ and $v$ in graph $G$ is denoted by $d_G(u,v)$. A cycle $C$ is called \\\\textit{chordless} if $C$ has no \\\\textit{cycle chord} (that is an edge not in the edge set of $C$ whose endpoints lie on the vertices of $C$).\\nThe \\\\textit{Induced subgraph} on vertex set $S$ is denoted by $\\\\langle S\\\\rangle$. A path that starts in $v$ and ends in $u$ is denoted by $\\\\stackrel\\\\frown{v u}$.\\nA \\\\textit{traceable} graph is a graph that possesses a Hamiltonian path.\\nIn a graph $G$, we say that a cycle $C$ is \\\\textit{formed by the path} $Q$ if $ | E(C) \\\\setminus E(Q) | = 1 $. So every vertex of $C$ belongs to $V(Q)$.\\n\\nIn 2011 the following conjecture was proposed:\\n\\\\begin{conjecture}(Hoffmann-Ostenhof \\\\cite{hoffman})\\nLet $G$ be a connected cubic graph. Then $G$ has a decomposition into a spanning tree, a matching and a family of cycles.\\n\\n\\\\end{conjecture}\\nConjecture \\\\theconjecture$\\\\,$ also appears in Problem 516 \\\\cite{cameron}. There are a few partial results known for Conjecture \\\\theconjecture. Kostochka \\\\cite{kostocha} noticed that the Petersen graph, the prisms over cycles, and many other graphs have a decomposition desired in Conjecture \\\\theconjecture. Ozeki and Ye \\\\cite{ozeki} proved that the conjecture holds for 3-connected cubic plane graphs. Furthermore, it was proved by Bachstein \\\\cite{bachstein} that Conjecture \\\\theconjecture$\\\\,$ is true for every 3-connected cubic graph embedded in torus or Klein-bottle. Akbari, Jensen and Siggers \\\\cite[Theorem 9]{akbari} showed that Conjecture \\\\theconjecture$\\\\,$ is true for Hamiltonian cubic graphs.\\n\\nIn this paper, we show that Conjecture \\\\theconjecture$\\\\,$ holds for traceable cubic graphs.\\n\\\\section{Results}\\nBefore proving the main result, we need the following lemma.\\n\\\\begin{lemma}\\n\\\\label{lemma:1}\\nLet $G$ be a cubic graph. Suppose that $V(G)$ can be partitioned into a tree $T$ and finitely many cycles such that there is no edge between any pair of cycles (not necessarily distinct cycles), and every pendant vertex of $T$ is adjacent to at least one vertex of a cycle. Then, Conjecture \\\\theconjecture$\\\\,$ holds for $G$.\\n\\\\end{lemma}\\n\\\\begin{proof}\\nBy assumption, every vertex of each cycle in the partition is adjacent to exactly one vertex of $T$. Call the set of all edges with one endpoint in a cycle and another endpoint in $T$ by $Q$.\\nClearly, the induced subgraph on $E(T) \\\\cup Q$ is a spanning tree of $G$. We call it $T'$. Note that every edge between a pendant vertex of $T$ and the union of cycles in the partition is also contained in $T'$. Thus, every pendant vertex of $T'$ is contained in a cycle of the partition. Now, consider the graph $H = G \\\\setminus E(T')$. For every $v \\\\in V(T)$, $d_H(v) \\\\leq 1$. So Conjecture \\\\theconjecture$\\\\,$ holds for $G$. \\\\vspace{1em}\\n\\\\end{proof}\\n\\n\\n\\\\noindent\\\\textbf{Remark 1.}\\n\\\\label{remark:1}\\nLet $C$ be a cycle formed by the path $Q$. Then clearly there exists a chordless cycle formed by $Q$.\\n\\nNow, we are in a position to prove the main result.\\n\\n\\\\begin{theorem}\\nConjecture \\\\theconjecture$\\\\,$ holds for traceable cubic graphs.\\n\\\\end{theorem}\\n\\\\begin{proof}\\nLet $G$ be a traceable cubic graph and $P : v_1, \\\\dots, v_n$ be a Hamiltonian path in $G$. By \\\\cite[Theorem 9]{akbari}, Conjecture A holds for $v_1 v_n  \\\\in E(G)$. Thus we can assume that $v_1 v_n  \\\\notin E(G)$. Let $v_1 v_j, v_1 v_{j'}, v_i v_n, v_{i'} v_n \\\\in E(G)\\\\setminus E(P)$  and $j' < j < n$, $1 < i < i'$. Two cases can occur:\\n\\\\begin{enumerate}[leftmargin=0pt,label=]\\n\\\\item\\n\\\\textbf{Case 1.}\\nAssume that $i < j$. Consider the following graph in Figure \\\\ref{fig:overlapping} in which the thick edges denote the path $P$. Call the three paths between $v_j$ and $v_i$, from the left to the right, by $P_1$, $P_2$ and $P_3$, respectively (note that $P_1$ contains the edge $e'$ and $P_3$ contains the edge $e$).\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=40mm]{engImages/overlapping.pdf}\\n    \\\\caption{Paths $P_1$, $P_2$ and $P_3$}\\n    \\\\label{fig:overlapping}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\n\\nIf $P_2$ has order $2$, then $G$ is Hamiltonian and so by \\\\cite[Theorem 9]{akbari} Conjecture \\\\theconjecture$\\\\,$ holds. Thus we can assume that $P_1$, $P_2$ and $P_3$ have order at least $3$. Now, consider the following subcases:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=0pt,label=]\\n\\\\label{case:1}\\n\\\\item \\\\textbf{Subcase 1.} There is no edge between $V(P_r)$ and $V(P_s)$ for $1 \\\\leq r < s \\\\leq 3$. Since every vertex of $P_i$ has degree 3 for every $i$, by \\\\hyperref[remark:1]{Remark 1}$\\\\,$ there are two chordless cycles $C_1$ and $C_2$ formed by $P_1$ and $P_2$, respectively.\\nDefine a tree $T$ with the edge set\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle\\\\Big) \\\\bigcap \\\\big(\\\\bigcup_{i=1}^3 E(P_i)\\\\big).$$\\nNow, apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\\\\\\\\\n\\n\\\\item \\\\textbf{Subcase 2.}\\n\\\\label{case:edge}\\nThere exists at least one edge between some $P_r$ and $P_s$, $r<s$. With no loss of generality, assume that $r=1$ and $s=2$. Suppose that $ab \\\\in E(G)$, where $a \\\\in V(P_1)$, $b \\\\in V(P_2)$ and $d_{P_1}(v_j, a) + d_{P_2}(v_j, b)$ is minimum.\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=40mm]{engImages/ab.pdf}\\n    \\\\caption{The edge $ab$ between $P_1$ and $P_2$}\\n    \\\\label{fig:ab}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\nThree cases occur: \\\\\\\\\\n\\n(a) There is no chordless cycle formed by either of the paths $\\\\stackrel\\\\frown{v_j a}$ or $\\\\stackrel\\\\frown{v_j b}$. Let $C$ be the chordless cycle $\\\\stackrel\\\\frown{v_j a}\\\\stackrel\\\\frown{ b v_j}$. Define $T$ with the edge set\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus V(C)\\\\rangle\\\\Big) \\\\bigcap \\\\big(\\\\bigcup_{i=1}^3 E(P_i)\\\\big).$$\\nNow, apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T,C\\\\}$.\\t\\\\\\\\\\n\\n(b) There are two chordless cycles, say $C_1$ and $C_2$, respectively formed by the paths $\\\\stackrel\\\\frown{v_j a}$ and $\\\\stackrel\\\\frown{v_j b}$. Now, consider the partition $C_1$, $C_2$ and the tree induced on the following edges,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle\\\\Big) \\\\; \\\\bigcap \\\\; E\\\\Big(\\\\bigcup_{i=1}^3 P_i\\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\\\\\\\\\n\\n(c) With no loss of generality, there exists a chordless cycle formed by the path $\\\\stackrel\\\\frown{v_j a}$ and there is no chordless cycle formed by the path $\\\\stackrel\\\\frown{v_j b}$.\\nFirst, suppose that for every chordless cycle $C_t$ on $\\\\stackrel\\\\frown{v_j a}$, at least one of the vertices of $C_t$ is adjacent to a vertex in $V(G) \\\\setminus V(P_1)$.\\nWe call one of the edges with one end in $C_t$ and other endpoint in $V(G) \\\\setminus V(P_1)$ by $e_t$. Let $v_j=w_0, w_1, \\\\dots, w_l=a$ be all vertices of the path $\\\\stackrel\\\\frown{v_j a}$ in $P_1$. Choose the shortest path $w_0 w_{i_1} w_{i_2} \\\\dots w_l$ such that $0 < i_1 < i_2 < \\\\dots < l$.\\nDefine a tree $T$ whose edge set is the thin edges in Figure \\\\ref{fig:deltaCycle}.\\\\\\\\\\nCall the cycle $w_0 w_{i_1} \\\\dots w_l \\\\stackrel\\\\frown{b w_0}$ by $C'$. Now, by removing $C'$, $q$ vertex disjoint paths $Q_1, \\\\dots, Q_q$ which are contained in $\\\\stackrel\\\\frown{v_j a}$ remain. Note that there exists a path of order $2$ in $C'$ which by adding this path to $Q_i$ we find a cycle $C_{t_i}$, for some $i$. Hence there exists an edge $e_{t_i}$ connecting $Q_i$ to $V(G) \\\\setminus V(P_1)$. Now, we define a tree $T$ whose the edge set is,\\n$$\\\\quad\\\\quad\\\\quad \\\\bigg( E\\\\Big(\\\\langle V(G) \\\\setminus V(C') \\\\rangle \\\\Big)\\\\; \\\\bigcap \\\\; \\\\Big(\\\\bigcup_{i=1}^3 E(P_i)\\\\Big) \\\\bigg) \\\\bigcup \\\\Big(\\\\big\\\\{e_{t_i} \\\\mid 1 \\\\leq i \\\\leq q \\\\big\\\\} \\\\Big).$$\\nApply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T,C'\\\\}$.\\\\\\\\\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=40mm]{engImages/deltaCycle.pdf}\\n    \\\\caption{The cycle $C'$ and the tree $T$}\\n       \\\\label{fig:deltaCycle}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\nNext, assume that there exists a cycle $C_1$ formed by $\\\\stackrel\\\\frown{v_j a}$ such that none of the vertices of $C_1$ is adjacent to $V(G) \\\\setminus V(P_1)$. Choose the smallest cycle with this property. Obviously, this cycle is chordless. Now, three cases can be considered:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=5pt,label=(\\\\roman*)]\\n\\\\item There exists a cycle $C_2$ formed by $P_2$ or $P_3$. Define the partition $C_1$, $C_2$ and a tree with the following edge set,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( \\\\bigcup_{i=1}^3 E(P_i) \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\\\\\\\\\n\\n\\\\item There is no chordless cycle formed by $P_2$ and by $P_3$, and there is at least one edge between $V(P_2)$ and $V(P_3)$. Let $ab \\\\in E(G)$, $a \\\\in V(P_2)$ and $b \\\\in V(P_3)$ and moreover $d_{P_2}(v_j, a) + d_{P_3}(v_j,b)$ is minimum. Notice that the cycle $\\\\stackrel\\\\frown{v_j a} \\\\stackrel\\\\frown{b v_j}$ is chordless. Let us call this cycle by $C_2$. Now, define the partition $C_2$ and a tree with the following edge set,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus V(C_2)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( \\\\bigcup_{i=1}^3 E(P_i) \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\\\\\\\\\n\\n\\\\item There is no chordless cycle formed by $P_2$ and by $P_3$, and there is no edge between $V(P_2)$ and $V(P_3)$. Let $C_2$ be the cycle consisting of two paths $P_2$ and $P_3$. Define the partition $C_2$ and a tree with the following edge set,\\n$$E\\\\Big(\\\\langle V(G) \\\\setminus V(C_2)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( \\\\bigcup_{i=1}^3 E(P_i) \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1}.\\n\\n\\\\end{enumerate}\\n\\n\\n\\\\end{enumerate}\\n\\n\\\\vspace{5mm}\\n\\\\item\\n\\\\textbf{Case 2.}\\n\\\\label{case:2}\\nAssume that $j < i$ for all Hamiltonian paths. Among all Hamiltonian paths consider the  path such that $i'-j'$ is maximum. Now, three cases can be considered:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=0pt,label=]\\n\\\\item \\\\textbf{Subcase 1.} There is no $s < j'$ and $t > i'$ such that $v_s v_t \\\\in E(G)$. By \\\\hyperref[remark:1]{Remark 1} $\\\\,$ there are two chordless cycles $C_1$ and $C_2$, respectively formed by the paths $v_1 v_{j'}$ and $v_{i'} v_n$. By assumption there is no edge $xy$, where $x \\\\in V(C_1)$ and $y \\\\in V(C_2)$.\\nDefine a tree $T$ with the edge set:\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_{i'}v_n, v_{j'}v_1\\\\} \\\\Big).$$\\nNow, apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\\\\\\\\\n\\n\\\\item \\\\textbf{Subcase 2.}\\n\\\\label{subcase:22} There are at least four indices $s, s' < j$ and $t, t' > i$ such that $v_s v_t, v_{s'} v_{t'} \\\\in E(G)$. Choose four indices $g, h < j$ and $e, f > i$ such that $v_h v_e, v_g v_f \\\\in E(G)$ and $|g-h| + |e-f|$ is minimum.\\n\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=90mm]{engImages/case2-subcase2.pdf}\\n    \\\\caption{Two edges $v_h v_e$ and $v_g v_f$}\\n    \\\\label{fig:non-overlapping}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\nThree cases can be considered:\\\\\\\\\\n\\n\\\\begin{enumerate}[leftmargin=0pt,label=(\\\\alph*)]\\n\\\\item There is no chordless cycle formed by $\\\\stackrel\\\\frown{v_g v_h}$ and by $\\\\stackrel\\\\frown{v_e v_f}$.\\n\\nConsider the cycle $\\\\stackrel\\\\frown{v_g v_h} \\\\stackrel\\\\frown{v_e v_f}v_g$ and call it $C$. Now, define a tree $T$ with the edge set,\\n$$\\\\,\\\\,\\\\,E\\\\Big(\\\\langle V(G) \\\\setminus V(C)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\napply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C\\\\}$.\\\\\\\\\\n\\n\\\\item With no loss of generality, there exists a chordless cycle formed by $\\\\stackrel\\\\frown{v_e v_f}$ and there is no chordless cycle formed by the path $\\\\stackrel\\\\frown{v_g v_h}$. First suppose that there is a chordless cycle $C_1$ formed by $\\\\stackrel\\\\frown{v_e v_f}$ such that there is no edge between $V(C_1)$ and $\\\\{v_1, \\\\dots, v_j\\\\}$. By \\\\hyperref[remark:1]{Remark 1} $,$ there exists a chordless cycle $C_2$ formed by $\\\\stackrel\\\\frown{v_1 v_j}$. By assumption there is no edge between $V(C_1)$ and $V(C_2)$. Now, define a tree $T$ with the edge set,\\n\\n$$\\\\quad\\\\quad\\\\quad\\\\quad E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\n\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\n\\n$\\\\;$ Next assume that for every cycle $C_r$ formed by $\\\\stackrel\\\\frown{v_e v_f}$, there are two vertices $x_r \\\\in V(C_r)$ and $y_r \\\\in \\\\{v_1, \\\\dots, v_j\\\\}$ such that $x_r y_r \\\\in E(G)$. Let $v_e=w_0, w_1, \\\\dots, w_l=v_f$ be all vertices of the path $\\\\stackrel\\\\frown{v_e v_f}$ in $P$. Choose the shortest path $w_0 w_{i_1} w_{i_2} \\\\dots w_l$ such that $0 < i_1 < i_2 < \\\\dots < l$. Consider the cycle $w_0 w_{i_1} \\\\dots w_l \\\\stackrel\\\\frown{v_g v_h}$ and call it $C$. Now, by removing $C$, $q$ vertex disjoint paths $Q_1, \\\\dots, Q_q$ which are contained in $\\\\stackrel\\\\frown{v_e v_f}$ remain. Note that there exists a path of order $2$ in $C$ which by adding this path to $Q_i$ we find a cycle $C_{r_i}$, for some $i$. Hence there exists an edge $x_{r_i} y_{r_i}$ connecting $Q_i$ to $V(G) \\\\setminus V(\\\\stackrel\\\\frown{v_e v_f})$. We define a tree $T$ whose edge set is the edges,\\n$$\\\\quad\\\\quad\\\\quad\\\\quad\\\\quad\\\\quad E\\\\Big(\\\\langle V(G) \\\\setminus V(C)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\cup \\\\big\\\\{x_{r_i} y_{r_i} \\\\mid 1 \\\\leq i \\\\leq q\\\\big\\\\} \\\\Big),$$\\nthen apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$ on the partition $\\\\{T, C\\\\}$.\\\\\\\\\\n\\\\begin{figure}[H]\\n  \\\\begin{center}\\n    \\\\includegraphics[width=90mm]{engImages/deltaNonOverlapping.pdf}\\n    \\\\caption{The tree $T$ and the shortest path $w_0 w_{i_1}\\\\dots w_l$}\\n    \\\\label{fig:delta-non-overlapping}\\n  \\\\end{center}\\n\\\\end{figure}\\n\\n\\\\item There are at least two chordless cycles, say $C_1$ and $C_2$ formed by the paths $\\\\stackrel\\\\frown{v_g v_h}$ and $\\\\stackrel\\\\frown{v_e v_f}$, respectively. Since $|g-h| + |e-f|$ is minimum, there is no edge $xy \\\\in E(G)$ with $x \\\\in V(C_1)$ and $y \\\\in V(C_2)$. Now, define a tree $T$ with the edge set,\\n$$\\\\quad\\\\quad\\\\quad\\\\quad E\\\\Big( \\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big) \\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1 v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition $\\\\{T, C_1, C_2\\\\}$.\\\\\\\\\\n\\\\end{enumerate}\\n\\n\\\\item \\\\textbf{Subcase 3.} There exist exactly two indices $s,t$,  $s < j' < i' < t$ such that $v_s v_t \\\\in E(G)$ and there are no two other indices $s', t'$ such that $s' < j < i < t'$ and $v_{s'} v_{t'} \\\\in E(G)$. We can assume that there is no cycle formed by  $\\\\stackrel\\\\frown{v_{s+1} v_j}$ or $\\\\stackrel\\\\frown{v_i v_{t-1}}$, to see this by symmetry consider a cycle $C$ formed by $\\\\stackrel\\\\frown{v_{s+1} v_j}$. By \\\\hyperref[remark:1]{Remark 1} $\\\\,$ there exist chordless cycles $C_1$ formed by $\\\\stackrel\\\\frown{v_{s+1} v_j}$ and $C_2$ formed by $\\\\stackrel\\\\frown{v_{i} v_n}$. By assumption $v_s v_t$ is the only edge such that $s < j$ and $t > i \\\\;$. Therefore,  there is no edge between $V(C_1)$ and  $V(C_2)$. Now, let $T$ be a tree defined by the edge set,\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_1v_{j}, v_{i}v_n\\\\} \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition \\\\{$T$, $C_1$, $C_2$\\\\}.\\\\\\\\\\n\\n$\\\\quad$Furthermore, we can also assume that either $s \\\\neq j'-1$  or $t \\\\neq i'+1$, otherwise we have the Hamiltonian cycle $\\\\stackrel\\\\frown{v_1 v_s} \\\\stackrel\\\\frown{v_t v_n} \\\\stackrel\\\\frown{v_{i'} v_{j'}} v_1$ and by \\\\cite[Theorem 9]{akbari} Conjecture \\\\theconjecture$\\\\,$ holds.\\n\\n$\\\\quad$By symmetry, suppose that $s \\\\neq j'-1$. Let $v_k$ be the vertex adjacent to $v_{j'-1}$, and $k \\\\notin \\\\{j'-2, j'\\\\}$. It can be shown that $k > j'-1$, since otherwise by considering the Hamiltonian path $P': \\\\; \\\\stackrel\\\\frown{ v_{k+1} v_{j'-1}}\\\\stackrel\\\\frown{v_k v_1} \\\\stackrel\\\\frown{v_{j'} v_n}$,  the new $i'-j'$ is greater than the old one and this contradicts our assumption about $P$ in the \\\\hyperref[case:2]{Case 2}.\\n\\n$\\\\quad$We know that $j' < k < i$. Moreover, the fact that  $\\\\stackrel\\\\frown{v_{s+1} v_j}$ does not form a cycle contradicts the case that $j' < k \\\\le j$. So $j < k < i$. Consider two cycles $C_1$ and $C_2$, respectively with the vertices $v_1 \\\\stackrel\\\\frown{v_{j'} v_{j}} v_1$ and $v_n \\\\stackrel\\\\frown{v_{i'} v_{i}} v_n$. The cycles $C_1$ and $C_2$ are chordless, otherwise there exist cycles formed by the paths $\\\\stackrel\\\\frown{v_{s+1} v_j}$ or $\\\\stackrel\\\\frown{v_i v_{t-1}}$. Now, define a tree $T$ with the edge set\\n$$ E\\\\Big(\\\\langle V(G) \\\\setminus \\\\big(V(C_1) \\\\cup V(C_2)\\\\big)\\\\rangle \\\\Big) \\\\bigcap \\\\Big( E(P) \\\\cup \\\\{v_s v_t, v_k v_{j'-1}\\\\} \\\\Big),$$\\nand apply \\\\hyperref[lemma:1]{Lemma 1} $\\\\,$for the partition \\\\{$T$, $C_1$, $C_2$\\\\}.\\n\\\\end{enumerate}\\n\\\\end{enumerate}\\n\\\\end{proof}\\n\\n\\\\noindent\\\\textbf{Remark 2.}\\n\\\\label{remark:2}\\nIndeed, in the proof of the previous theorem we showed a stronger result, that is, for every traceable cubic graph there is a decomposition with at most two cycles.\\n\\n\",\n",
       " 'meta': {'timestamp': '2016-07-19T02:04:55',\n",
       "  'yymm': '1607',\n",
       "  'arxiv_id': '1607.04768',\n",
       "  'language': 'en',\n",
       "  'url': 'https://arxiv.org/abs/1607.04768'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791621a4536545409259e21476c52c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c1ff3e2924429881e70426c6bdf451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20999ba609284bb8a8aa15a4161de0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read file '/home/jason/revolution/data/redpajama/arxiv/arxiv_024de5df-1b7f-447c-8c3a-51407d8d6732.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Missing a closing quotation mark in string. in row 22\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/packaged_modules/json/json.py:144\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    142\u001b[0m         file, encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mencoding, errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mencoding_errors\n\u001b[1;32m    143\u001b[0m     ) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 144\u001b[0m         dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m    145\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39ma JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[1;32m    294\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m, object_hook\u001b[39m=\u001b[39;49mobject_hook,\n\u001b[1;32m    295\u001b[0m     parse_float\u001b[39m=\u001b[39;49mparse_float, parse_int\u001b[39m=\u001b[39;49mparse_int,\n\u001b[1;32m    296\u001b[0m     parse_constant\u001b[39m=\u001b[39;49mparse_constant, object_pairs_hook\u001b[39m=\u001b[39;49mobject_pairs_hook, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExtra data\u001b[39m\u001b[39m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 159829)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/builder.py:1925\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   1924\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 1925\u001b[0m \u001b[39mfor\u001b[39;00m _, table \u001b[39min\u001b[39;00m generator:\n\u001b[1;32m   1926\u001b[0m     \u001b[39mif\u001b[39;00m max_shard_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m writer\u001b[39m.\u001b[39m_num_bytes \u001b[39m>\u001b[39m max_shard_size:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/packaged_modules/json/json.py:147\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    146\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to read file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with error \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    148\u001b[0m \u001b[39m# If possible, parse the file as a list of json objects and exit the loop\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/packaged_modules/json/json.py:121\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     pa_table \u001b[39m=\u001b[39m paj\u001b[39m.\u001b[39;49mread_json(\n\u001b[1;32m    122\u001b[0m         io\u001b[39m.\u001b[39;49mBytesIO(batch), read_options\u001b[39m=\u001b[39;49mpaj\u001b[39m.\u001b[39;49mReadOptions(block_size\u001b[39m=\u001b[39;49mblock_size)\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pyarrow/_json.pyx:258\u001b[0m, in \u001b[0;36mpyarrow._json.read_json\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: JSON parse error: Missing a closing quotation mark in string. in row 22",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39;49m\u001b[39mjson\u001b[39;49m\u001b[39m'\u001b[39;49m, data_files\u001b[39m=\u001b[39;49mfile_paths, split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/load.py:2133\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   2132\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2133\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   2134\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2135\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2136\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   2137\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   2138\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   2139\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2140\u001b[0m )\n\u001b[1;32m   2142\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2143\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   2144\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   2145\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/builder.py:954\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m--> 954\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    955\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    956\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m    957\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    958\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/builder.py:1049\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m split_dict\u001b[39m.\u001b[39madd(split_generator\u001b[39m.\u001b[39msplit_info)\n\u001b[1;32m   1047\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1048\u001b[0m     \u001b[39m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_split(split_generator, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs)\n\u001b[1;32m   1050\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m   1052\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find data file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1053\u001b[0m         \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1054\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m   1056\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/builder.py:1813\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[0;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1811\u001b[0m job_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1812\u001b[0m \u001b[39mwith\u001b[39;00m pbar:\n\u001b[0;32m-> 1813\u001b[0m     \u001b[39mfor\u001b[39;00m job_id, done, content \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_split_single(\n\u001b[1;32m   1814\u001b[0m         gen_kwargs\u001b[39m=\u001b[39mgen_kwargs, job_id\u001b[39m=\u001b[39mjob_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_prepare_split_args\n\u001b[1;32m   1815\u001b[0m     ):\n\u001b[1;32m   1816\u001b[0m         \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   1817\u001b[0m             result \u001b[39m=\u001b[39m content\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/datasets/builder.py:1958\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[1;32m   1956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, SchemaInferenceError) \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39m__context__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m         e \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39m__context__\n\u001b[0;32m-> 1958\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetGenerationError(\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while generating the dataset\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m \u001b[39myield\u001b[39;00m job_id, \u001b[39mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[39m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('json', data_files=file_paths, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:  https://data.together.xyz/redpajama-data-1T/v1.0.0/github/filtered_7fa232e63a5d44a88a267181e9ac47b4.sampled.jsonl\n",
      "dload_loc:  redpajama-data-1T/v1.0.0/github/filtered_7fa232e63a5d44a88a267181e9ac47b4.sampled.jsonl\n",
      "dirname(dload_loc): redpajama-data-1T/v1.0.0/github\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Get all URLS.\n",
    "url = 'https://data.together.xyz/redpajama-data-1T/v1.0.0/urls.txt'\n",
    "response = requests.get(url)\n",
    "all_urls = response.content.decode('utf-8').split('\\n')\n",
    "\n",
    "# Create download folder.\n",
    "file = random.choice(all_urls)\n",
    "print(\"file: \", file)\n",
    "dload_loc = urlparse(file).path[1:]\n",
    "print(\"dload_loc: \", dload_loc)\n",
    "os.makedirs(os.path.dirname(dload_loc), exist_ok=True) \n",
    "print(\"dirname(dload_loc):\", os.path.dirname(dload_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to:  /home/jason/redpajama-data-1T/v1.0.0/github/filtered_7fa232e63a5d44a88a267181e9ac47b4.sampled.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8440885it [03:51, 36520.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download data.\n",
    "path = os.path.expanduser( \"~/\" + dload_loc )\n",
    "print(\"writing to:\", path)\n",
    "r = requests.get(file, stream=True)\n",
    "with open(os.path.expanduser( \"~/\" + dload_loc ), 'wb') as f:\n",
    "    for chunk in tqdm(r.iter_content(1024)):\n",
    "        f.write(chunk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load dataset.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ds \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m, data_files \u001b[39m=\u001b[39m path)\n\u001b[1;32m      3\u001b[0m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(ds[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "ds = load_dataset('json', data_files = path)\n",
    "next(iter(ds['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jason/redpajama-data-1T/v1.0.0/common_crawl/2021-04/en_head_0025.json.gz.dedup.classifier.jsonl.zst'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'redpajama-data-1T/v1.0.0/common_crawl/2021-04/en_head_0025.json.gz.dedup.classifier.jsonl.zst'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dload_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jason/redpajama-data-1T/v1.0.0/common_crawl/2021-04/en_head_0025.json.gz.dedup.classifier.jsonl.zst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m file_path \u001b[39m=\u001b[39m path\n\u001b[1;32m      6\u001b[0m \u001b[39m# Open the file and read the first line\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      8\u001b[0m     first_line \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreadline()\n\u001b[1;32m     10\u001b[0m \u001b[39m# Load the line as JSON\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jason/redpajama-data-1T/v1.0.0/common_crawl/2021-04/en_head_0025.json.gz.dedup.classifier.jsonl.zst'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Replace with the path to your JSONL file\n",
    "file_path = path\n",
    "\n",
    "# Open the file and read the first line\n",
    "with open(file_path, 'r') as file:\n",
    "    first_line = file.readline()\n",
    "\n",
    "# Load the line as JSON\n",
    "json_object = json.loads(first_line)\n",
    "\n",
    "# Get the keys (i.e., the features)\n",
    "features = json_object.keys()\n",
    "\n",
    "print(features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
